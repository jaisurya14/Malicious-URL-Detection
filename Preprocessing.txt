import numpy as npimport pandas as pdimport matplotlib.pyplot as plt%matplotlib inlineimport seaborn as snsfrom sklearn import metrics import warningswarnings.filterwarnings('ignore')data = pd.read_csv("malicious.csv")data.head()plt.figure(figsize=(15,15))sns.heatmap(data.corr(), annot=True)plt.show()df = data[['PrefixSuffix-', 'SubDomains', 'HTTPS','AnchorURL','WebsiteTraffic','class']]sns.pairplot(data = df,hue="class",corner=True);X = data.drop(["class"],axis =1)y = data["class"]from sklearn.model_selection import train_test_splitX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)X_train.shape, y_train.shape, X_test.shape, y_test.shapeML_Model = []accuracy = []f1_score = []recall = []precision = []def storeResults(model, a,b,c,d):  ML_Model.append(model)  accuracy.append(round(a, 3))  f1_score.append(round(b, 3))  recall.append(round(c, 3))  precision.append(round(d, 3))from sklearn.svm import SVCfrom sklearn.model_selection import GridSearchCVparam_grid = {'gamma': [0.1],'kernel': ['rbf','linear']}svc = GridSearchCV(SVC(), param_grid)svc.fit(X_train, y_train)y_train_svc = svc.predict(X_train)y_test_svc = svc.predict(X_test)acc_train_svc = metrics.accuracy_score(y_train,y_train_svc)acc_test_svc = metrics.accuracy_score(y_test,y_test_svc)print("Support Vector Machine : Accuracy on training Data: {:.3f}".format(acc_train_svc))print("Support Vector Machine : Accuracy on test Data: {:.3f}".format(acc_test_svc))print()f1_score_train_svc = metrics.f1_score(y_train,y_train_svc)f1_score_test_svc = metrics.f1_score(y_test,y_test_svc)print("Support Vector Machine : f1_score on training Data: {:.3f}".format(f1_score_train_svc))print("Support Vector Machine : f1_score on test Data: {:.3f}".format(f1_score_test_svc))print()recall_score_train_svc = metrics.recall_score(y_train,y_train_svc)recall_score_test_svc = metrics.recall_score(y_test,y_test_svc)print("Support Vector Machine : Recall on training Data: {:.3f}".format(recall_score_train_svc))print("Support Vector Machine : Recall on test Data: {:.3f}".format(recall_score_test_svc))print()precision_score_train_svc = metrics.precision_score(y_train,y_train_svc)precision_score_test_svc = metrics.precision_score(y_test,y_test_svc)print("Support Vector Machine : precision on training Data: {:.3f}".format(precision_score_train_svc))print("Support Vector Machine : precision on test Data: {:.3f}".format(precision_score_test_svc))print(metrics.classification_report(y_test, y_test_svc))storeResults('Support Vector Machine',acc_test_svc,f1_score_test_svc,             recall_score_train_svc,precision_score_train_svc)from sklearn.tree import DecisionTreeClassifiertree = DecisionTreeClassifier(max_depth=30)tree.fit(X_train, y_train)y_train_tree = tree.predict(X_train)y_test_tree = tree.predict(X_test)acc_train_tree = metrics.accuracy_score(y_train,y_train_tree)acc_test_tree = metrics.accuracy_score(y_test,y_test_tree)print("Decision Tree : Accuracy on training Data: {:.3f}".format(acc_train_tree))print("Decision Tree : Accuracy on test Data: {:.3f}".format(acc_test_tree))print()f1_score_train_tree = metrics.f1_score(y_train,y_train_tree)f1_score_test_tree = metrics.f1_score(y_test,y_test_tree)print("Decision Tree : f1_score on training Data: {:.3f}".format(f1_score_train_tree))print("Decision Tree : f1_score on test Data: {:.3f}".format(f1_score_test_tree))print()recall_score_train_tree = metrics.recall_score(y_train,y_train_tree)recall_score_test_tree = metrics.recall_score(y_test,y_test_tree)print("Decision Tree : Recall on training Data: {:.3f}".format(recall_score_train_tree))print("Decision Tree : Recall on test Data: {:.3f}".format(recall_score_test_tree))print()precision_score_train_tree = metrics.precision_score(y_train,y_train_tree)precision_score_test_tree = metrics.precision_score(y_test,y_test_tree)print("Decision Tree : precision on training Data: {:.3f}".format(precision_score_train_tree))print("Decision Tree : precision on test Data: {:.3f}".format(precision_score_test_tree))print(metrics.classification_report(y_test, y_test_tree))from sklearn.ensemble import RandomForestClassifierforest = RandomForestClassifier(n_estimators=10)forest.fit(X_train,y_train)y_train_forest = forest.predict(X_train)y_test_forest = forest.predict(X_test)acc_train_forest = metrics.accuracy_score(y_train,y_train_forest)acc_test_forest = metrics.accuracy_score(y_test,y_test_forest)print("Random Forest : Accuracy on training Data: {:.3f}".format(acc_train_forest))print("Random Forest : Accuracy on test Data: {:.3f}".format(acc_test_forest))print()f1_score_train_forest = metrics.f1_score(y_train,y_train_forest)f1_score_test_forest = metrics.f1_score(y_test,y_test_forest)print("Random Forest : f1_score on training Data: {:.3f}".format(f1_score_train_forest))print("Random Forest : f1_score on test Data: {:.3f}".format(f1_score_test_forest))print()recall_score_train_forest = metrics.recall_score(y_train,y_train_forest)recall_score_test_forest = metrics.recall_score(y_test,y_test_forest)print("Random Forest : Recall on training Data: {:.3f}".format(recall_score_train_forest))print("Random Forest : Recall on test Data: {:.3f}".format(recall_score_test_forest))print()precision_score_train_forest = metrics.precision_score(y_train,y_train_forest)precision_score_test_forest = metrics.precision_score(y_test,y_test_tree)print("Random Forest : precision on training Data: {:.3f}".format(precision_score_train_forest))print("Random Forest : precision on test Data: {:.3f}".format(precision_score_test_forest))print(metrics.classification_report(y_test, y_test_forest))training_accuracy = []test_accuracy = []depth = range(1,20)for n in depth:    forest_test =  RandomForestClassifier(n_estimators=n)    forest_test.fit(X_train, y_train)       training_accuracy.append(forest_test.score(X_train, y_train))        test_accuracy.append(forest_test.score(X_test, y_test))    plt.figure(figsize=None)plt.plot(depth, training_accuracy, label="training accuracy")plt.plot(depth, test_accuracy, label="test accuracy")plt.ylabel("Accuracy")  plt.xlabel("n_estimators")plt.legend();storeResults('Random Forest',acc_test_forest,f1_score_test_forest,             recall_score_train_forest,precision_score_train_forest)result = pd.DataFrame({ 'ML Model' : ML_Model,                        'Accuracy' : accuracy,                        'f1_score' : f1_score,                        'Recall'   : recall,                        'Precision': precision,                      })resultsorted_result=result.sort_values(by=['Accuracy', 'f1_score'],ascending=False).reset_index(drop=True)sorted_resultimport picklepickle.dump(gbc, open('pickle/model.pkl', 'wb'))generic_feature_names = [f'feature{i}' for i in range(X_train.shape[1])]  # Replace with your actual feature namesplt.figure(figsize=(9, 7))n_features = X_train.shape[1]plt.barh(range(n_features), gbc.feature_importances_, align='center')plt.yticks(np.arange(n_features), generic_feature_names)  # Use the generic feature names hereplt.title("Feature importances using permutation on the full model")plt.xlabel("Feature importance")plt.ylabel("Feature")plt.show()